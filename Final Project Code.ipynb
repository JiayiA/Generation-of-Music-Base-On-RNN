{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name: Jiayi Zhang\n",
    "#### Student ID: A14533542\n",
    "#### Date: July.18th 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 190 Final Project\n",
    "\n",
    "### Project Title: Generate K-Pop Music Base On RNN Model and Music Structure \n",
    "\n",
    "\n",
    "\n",
    "The dataset is quite small (around 90 files) and some of them includes the entire song that played piano on different tracks and some of them includes only an fragment of the song (mostly Intro or Chorus of the song) that's also mainly played by piano. The intention of the project is to separate the dataset into different segments based on the most simplified music structure that's commonly used in K-Pop music. (Riff/Intro->Verse1->Pre-Chorus->Chorus->Verse2->Pre-Chorus->Chorus->Riff/Outro) Verse1 and Verse2 will be both considered as Verse out of simplicity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from numpy.random import multinomial as randm\n",
    "from numpy import where\n",
    "import scipy.signal as si\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import scipy\n",
    "from matplotlib import patches\n",
    "import librosa.display as ld\n",
    "import music21\n",
    "from music21 import midi as midi21\n",
    "import mido\n",
    "from jchord.progressions import ChordProgression\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from numpy.linalg import svd\n",
    "from scipy.stats.mstats import gmean\n",
    "from matplotlib import rcParams\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import pickle\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.layers import Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm using the network straight from Assignment 3 because it will be hard to create my own network. \n",
    "def create_network(network_input, n_vocab):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        recurrent_dropout=0.3,\n",
    "    ))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Lambda(lambda network_input: network_input / 0.6))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        256,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    print(n_vocab)\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Lambda(lambda network_input: network_input / 0.6))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_note(total, stamp, element, Intro, Verse, Chorus, Outro):\n",
    "    if(stamp <= total*0.05):\n",
    "        Intro.append(str(element.pitch))\n",
    "    elif(stamp <= total*0.22):\n",
    "        Verse.append(str(element.pitch))\n",
    "    elif(stamp <= total*0.39):\n",
    "        Chorus.append(str(element.pitch))\n",
    "    elif(stamp <= total*0.56):\n",
    "        Verse.append(str(element.pitch))\n",
    "    elif(stamp <= total*0.73):\n",
    "        Chorus.append(str(element.pitch))\n",
    "    elif(stamp <= total*0.9):\n",
    "        Verse.append(str(element.pitch))\n",
    "    else:\n",
    "        Outro.append(str(element.pitch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_chord(total, stamp, element, Intro, Verse, Chorus, Outro):\n",
    "    if(stamp <= total*0.05):\n",
    "        Intro.append('.'.join(str(n) for n in [p.midi for p in element.pitches]))\n",
    "    elif(stamp <= total*0.22):\n",
    "        Verse.append('.'.join(str(n) for n in [p.midi for p in element.pitches]))\n",
    "    elif(stamp <= total*0.39):\n",
    "        Chorus.append('.'.join(str(n) for n in [p.midi for p in element.pitches]))\n",
    "    elif(stamp <= total*0.56):\n",
    "        Verse.append('.'.join(str(n) for n in [p.midi for p in element.pitches]))\n",
    "    elif(stamp <= total*0.73):\n",
    "        Chorus.append('.'.join(str(n) for n in [p.midi for p in element.pitches]))\n",
    "    elif(stamp <= total*0.9):\n",
    "        Verse.append('.'.join(str(n) for n in [p.midi for p in element.pitches]))\n",
    "    else:\n",
    "        Outro.append('.'.join(str(n) for n in [p.midi for p in element.pitches]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_timestamp():\n",
    "    \n",
    "    Intro = []\n",
    "    Verse = []\n",
    "    Chorus = []\n",
    "    Outro = []\n",
    "    \n",
    "    for file in glob.glob(\"COPY/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "        print(\"Parsing %s\" % file)\n",
    "        notes_to_parse = None\n",
    "        try:\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts['Piano'].recurse()\n",
    "        except:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        \n",
    "        totalLength = midi.highestTime\n",
    "        \n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                put_note(totalLength, element.offset, element, Intro, Verse, Chorus, Outro)\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                put_chord(totalLength, element.offset, element, Intro, Verse, Chorus, Outro)\n",
    "                \n",
    "    pickle.dump(Intro, open('Intro.p', 'wb'))\n",
    "    pickle.dump(Verse, open('Verse.p', 'wb'))\n",
    "    pickle.dump(Chorus, open('Chorus.p', 'wb'))\n",
    "    pickle.dump(Outro, open('Outro.p', 'wb'))\n",
    "    \n",
    "    return(Intro, Verse, Chorus, Outro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offset_difference():\n",
    "    \n",
    "    offset = []\n",
    "    difference = []\n",
    "    \n",
    "    for file in glob.glob(\"COPY/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "        print(\"Parsing %s\" % file)\n",
    "        offset_to_parse = None\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            offset_to_parse = s2.parts['Piano'].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            offset_to_parse = midi.flat.notes\n",
    "            \n",
    "        #Store each notes and the duration it's played in the music as a key-value pair\n",
    "        for element in offset_to_parse:\n",
    "            offset.append(element.offset)\n",
    "        \n",
    "        for index in range(len(offset)-1):\n",
    "            difference.append(offset[index+1]-offset[index])\n",
    "            \n",
    "            \n",
    "    pickle.dump(difference, open('offset.p', 'wb'))\n",
    "    \n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 40\n",
    "\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing COPY/dean-invisible.mid\n",
      "Parsing COPY/IU-Love-Poem.mid\n",
      "Parsing COPY/pick-me.mid\n",
      "Parsing COPY/hangzoo-red-sun.mid\n",
      "Parsing COPY/btob-ill-be-your-man.mid\n",
      "Parsing COPY/eric-you-who.mid\n",
      "Parsing COPY/IU-BBIBBI.mid\n",
      "Parsing COPY/fx-sorry-dear-daddy.mid\n",
      "Parsing COPY/vromance-im-fine.mid\n",
      "Parsing COPY/infinite-bad.mid\n",
      "Parsing COPY/nuest-w-just-one-day.mid\n",
      "Parsing COPY/girls-day-ill-be-yours.mid\n",
      "Parsing COPY/chief.-be-here-now.mid\n",
      "Parsing COPY/half-moon.mid\n",
      "Parsing COPY/BTS (방탄소년단) feat. Halsey - 작은 것들을 위한 시 (Boy With Luv)  (midi by Carlo Prato) (www.cprato.com).mid\n",
      "Parsing COPY/zion-t-the-song.mid\n",
      "Parsing COPY/blackpink.mid\n",
      "Parsing COPY/Dreamcatcher-Deja-Vu.mid\n",
      "Parsing COPY/block-b-yesterday.mid\n",
      "Parsing COPY/btob-someday.mid\n",
      "Parsing COPY/bigbang-last-dance.mid\n",
      "Parsing COPY/dean-come-over.mid\n",
      "Parsing COPY/iu-heart.mid\n",
      "Parsing COPY/2A - San E - Bad Year.mid\n",
      "Parsing COPY/sejeong-flower-road.mid\n",
      "Parsing COPY/dean-what2do.mid\n",
      "Parsing COPY/gfriend-fingertip.mid\n",
      "Parsing COPY/bolbbagan4-tell-me-you-love-me.mid\n",
      "Parsing COPY/girls-generation-lion-heart.mid\n",
      "Parsing COPY/twice-knock-knock.mid\n",
      "135\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_590 (LSTM)              (None, 40, 256)           264192    \n",
      "_________________________________________________________________\n",
      "dropout_589 (Dropout)        (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_591 (LSTM)              (None, 40, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "dropout_590 (Dropout)        (None, 40, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_592 (LSTM)              (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_498 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_591 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_499 (Dense)            (None, 135)               34695     \n",
      "_________________________________________________________________\n",
      "lambda_249 (Lambda)          (None, 135)               0         \n",
      "_________________________________________________________________\n",
      "activation_407 (Activation)  (None, 135)               0         \n",
      "=================================================================\n",
      "Total params: 4,104,327\n",
      "Trainable params: 4,104,327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/4\n",
      "  3/124 [..............................] - ETA: 37:24 - loss: 6.0780"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-a2936c1ae706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain_duration_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-235-a2936c1ae706>\u001b[0m in \u001b[0;36mtrain_duration_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Your line of code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtrain_duration_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_duration_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    durations = get_offset_difference()\n",
    "\n",
    "    n_vocab = len(set(durations))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(durations, n_vocab)\n",
    "    \n",
    "    model = create_network(network_input, n_vocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"final-duration-weights.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(network_input, network_output, epochs=4, batch_size=3000, callbacks=callbacks_list)\n",
    "\n",
    "train_duration_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing COPY/dean-invisible.mid\n",
      "Parsing COPY/IU-Love-Poem.mid\n",
      "Parsing COPY/pick-me.mid\n",
      "Parsing COPY/hangzoo-red-sun.mid\n",
      "Parsing COPY/btob-ill-be-your-man.mid\n",
      "Parsing COPY/eric-you-who.mid\n",
      "Parsing COPY/IU-BBIBBI.mid\n",
      "Parsing COPY/fx-sorry-dear-daddy.mid\n",
      "Parsing COPY/vromance-im-fine.mid\n",
      "Parsing COPY/infinite-bad.mid\n",
      "Parsing COPY/nuest-w-just-one-day.mid\n",
      "Parsing COPY/girls-day-ill-be-yours.mid\n",
      "Parsing COPY/chief.-be-here-now.mid\n",
      "Parsing COPY/half-moon.mid\n",
      "Parsing COPY/BTS (방탄소년단) feat. Halsey - 작은 것들을 위한 시 (Boy With Luv)  (midi by Carlo Prato) (www.cprato.com).mid\n",
      "Parsing COPY/zion-t-the-song.mid\n",
      "Parsing COPY/blackpink.mid\n",
      "Parsing COPY/Dreamcatcher-Deja-Vu.mid\n",
      "Parsing COPY/block-b-yesterday.mid\n",
      "Parsing COPY/btob-someday.mid\n",
      "Parsing COPY/bigbang-last-dance.mid\n",
      "Parsing COPY/dean-come-over.mid\n",
      "Parsing COPY/iu-heart.mid\n",
      "Parsing COPY/2A - San E - Bad Year.mid\n",
      "Parsing COPY/sejeong-flower-road.mid\n",
      "Parsing COPY/dean-what2do.mid\n",
      "Parsing COPY/gfriend-fingertip.mid\n",
      "Parsing COPY/bolbbagan4-tell-me-you-love-me.mid\n",
      "Parsing COPY/girls-generation-lion-heart.mid\n",
      "Parsing COPY/twice-knock-knock.mid\n",
      "Epoch 1/4\n",
      "157/157 [==============================] - 60s 383ms/step - loss: 5.2588\n",
      "Epoch 2/4\n",
      "157/157 [==============================] - 105s 667ms/step - loss: 4.9850\n",
      "Epoch 3/4\n",
      "157/157 [==============================] - 107s 685ms/step - loss: 4.9336\n",
      "Epoch 4/4\n",
      "157/157 [==============================] - 107s 681ms/step - loss: 4.9021\n"
     ]
    }
   ],
   "source": [
    "def train_Chorus_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    Intro, Verse, Chorus, Outro = group_by_timestamp()\n",
    "\n",
    "    n_vocab = len(set(Chorus))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(Chorus, n_vocab)\n",
    "    \n",
    "    model = create_network(network_input, n_vocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"final-Chorus-weights.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(network_input, network_output, epochs=4, batch_size=50, callbacks=callbacks_list)\n",
    "\n",
    "train_Chorus_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing COPY/dean-invisible.mid\n",
      "Parsing COPY/IU-Love-Poem.mid\n",
      "Parsing COPY/pick-me.mid\n",
      "Parsing COPY/hangzoo-red-sun.mid\n",
      "Parsing COPY/btob-ill-be-your-man.mid\n",
      "Parsing COPY/eric-you-who.mid\n",
      "Parsing COPY/IU-BBIBBI.mid\n",
      "Parsing COPY/fx-sorry-dear-daddy.mid\n",
      "Parsing COPY/vromance-im-fine.mid\n",
      "Parsing COPY/infinite-bad.mid\n",
      "Parsing COPY/nuest-w-just-one-day.mid\n",
      "Parsing COPY/girls-day-ill-be-yours.mid\n",
      "Parsing COPY/chief.-be-here-now.mid\n",
      "Parsing COPY/half-moon.mid\n",
      "Parsing COPY/BTS (방탄소년단) feat. Halsey - 작은 것들을 위한 시 (Boy With Luv)  (midi by Carlo Prato) (www.cprato.com).mid\n",
      "Parsing COPY/zion-t-the-song.mid\n",
      "Parsing COPY/blackpink.mid\n",
      "Parsing COPY/Dreamcatcher-Deja-Vu.mid\n",
      "Parsing COPY/block-b-yesterday.mid\n",
      "Parsing COPY/btob-someday.mid\n",
      "Parsing COPY/bigbang-last-dance.mid\n",
      "Parsing COPY/dean-come-over.mid\n",
      "Parsing COPY/iu-heart.mid\n",
      "Parsing COPY/2A - San E - Bad Year.mid\n",
      "Parsing COPY/sejeong-flower-road.mid\n",
      "Parsing COPY/dean-what2do.mid\n",
      "Parsing COPY/gfriend-fingertip.mid\n",
      "Parsing COPY/bolbbagan4-tell-me-you-love-me.mid\n",
      "Parsing COPY/girls-generation-lion-heart.mid\n",
      "Parsing COPY/twice-knock-knock.mid\n",
      "Epoch 1/4\n",
      "225/225 [==============================] - 153s 681ms/step - loss: 5.2051\n",
      "Epoch 2/4\n",
      "225/225 [==============================] - 154s 686ms/step - loss: 5.0093\n",
      "Epoch 3/4\n",
      "225/225 [==============================] - 132s 587ms/step - loss: 4.9432\n",
      "Epoch 4/4\n",
      "225/225 [==============================] - 89s 394ms/step - loss: 4.9150\n"
     ]
    }
   ],
   "source": [
    "def train_Verse_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    Intro, Verse, Chorus, Outro = group_by_timestamp()\n",
    "\n",
    "    n_vocab = len(set(Verse))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(Verse, n_vocab)\n",
    "    \n",
    "    model = create_network(network_input, n_vocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"final-Verse-weights.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(network_input, network_output, epochs=4, batch_size=50, callbacks=callbacks_list)\n",
    "\n",
    "train_Verse_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing COPY/dean-invisible.mid\n",
      "Parsing COPY/IU-Love-Poem.mid\n",
      "Parsing COPY/pick-me.mid\n",
      "Parsing COPY/hangzoo-red-sun.mid\n",
      "Parsing COPY/btob-ill-be-your-man.mid\n",
      "Parsing COPY/eric-you-who.mid\n",
      "Parsing COPY/IU-BBIBBI.mid\n",
      "Parsing COPY/fx-sorry-dear-daddy.mid\n",
      "Parsing COPY/vromance-im-fine.mid\n",
      "Parsing COPY/infinite-bad.mid\n",
      "Parsing COPY/nuest-w-just-one-day.mid\n",
      "Parsing COPY/girls-day-ill-be-yours.mid\n",
      "Parsing COPY/chief.-be-here-now.mid\n",
      "Parsing COPY/half-moon.mid\n",
      "Parsing COPY/BTS (방탄소년단) feat. Halsey - 작은 것들을 위한 시 (Boy With Luv)  (midi by Carlo Prato) (www.cprato.com).mid\n",
      "Parsing COPY/zion-t-the-song.mid\n",
      "Parsing COPY/blackpink.mid\n",
      "Parsing COPY/Dreamcatcher-Deja-Vu.mid\n",
      "Parsing COPY/block-b-yesterday.mid\n",
      "Parsing COPY/btob-someday.mid\n",
      "Parsing COPY/bigbang-last-dance.mid\n",
      "Parsing COPY/dean-come-over.mid\n",
      "Parsing COPY/iu-heart.mid\n",
      "Parsing COPY/2A - San E - Bad Year.mid\n",
      "Parsing COPY/sejeong-flower-road.mid\n",
      "Parsing COPY/dean-what2do.mid\n",
      "Parsing COPY/gfriend-fingertip.mid\n",
      "Parsing COPY/bolbbagan4-tell-me-you-love-me.mid\n",
      "Parsing COPY/girls-generation-lion-heart.mid\n",
      "Parsing COPY/twice-knock-knock.mid\n",
      "Epoch 1/4\n",
      "17/17 [==============================] - 6s 366ms/step - loss: 4.9935\n",
      "Epoch 2/4\n",
      "17/17 [==============================] - 6s 371ms/step - loss: 4.5412\n",
      "Epoch 3/4\n",
      "17/17 [==============================] - 6s 376ms/step - loss: 4.5214\n",
      "Epoch 4/4\n",
      "17/17 [==============================] - 6s 365ms/step - loss: 4.5238\n"
     ]
    }
   ],
   "source": [
    "def train_Intro_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    Intro, Verse, Chorus, Outro = group_by_timestamp()\n",
    "\n",
    "    n_vocab = len(set(Intro))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(Intro, n_vocab)\n",
    "    \n",
    "    model = create_network(network_input, n_vocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"final-Intro-weights.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(network_input, network_output, epochs=4, batch_size=50, callbacks=callbacks_list)\n",
    "\n",
    "train_Intro_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing COPY/dean-invisible.mid\n",
      "Parsing COPY/IU-Love-Poem.mid\n",
      "Parsing COPY/pick-me.mid\n",
      "Parsing COPY/hangzoo-red-sun.mid\n",
      "Parsing COPY/btob-ill-be-your-man.mid\n",
      "Parsing COPY/eric-you-who.mid\n",
      "Parsing COPY/IU-BBIBBI.mid\n",
      "Parsing COPY/fx-sorry-dear-daddy.mid\n",
      "Parsing COPY/vromance-im-fine.mid\n",
      "Parsing COPY/infinite-bad.mid\n",
      "Parsing COPY/nuest-w-just-one-day.mid\n",
      "Parsing COPY/girls-day-ill-be-yours.mid\n",
      "Parsing COPY/chief.-be-here-now.mid\n",
      "Parsing COPY/half-moon.mid\n",
      "Parsing COPY/BTS (방탄소년단) feat. Halsey - 작은 것들을 위한 시 (Boy With Luv)  (midi by Carlo Prato) (www.cprato.com).mid\n",
      "Parsing COPY/zion-t-the-song.mid\n",
      "Parsing COPY/blackpink.mid\n",
      "Parsing COPY/Dreamcatcher-Deja-Vu.mid\n",
      "Parsing COPY/block-b-yesterday.mid\n",
      "Parsing COPY/btob-someday.mid\n",
      "Parsing COPY/bigbang-last-dance.mid\n",
      "Parsing COPY/dean-come-over.mid\n",
      "Parsing COPY/iu-heart.mid\n",
      "Parsing COPY/2A - San E - Bad Year.mid\n",
      "Parsing COPY/sejeong-flower-road.mid\n",
      "Parsing COPY/dean-what2do.mid\n",
      "Parsing COPY/gfriend-fingertip.mid\n",
      "Parsing COPY/bolbbagan4-tell-me-you-love-me.mid\n",
      "Parsing COPY/girls-generation-lion-heart.mid\n",
      "Parsing COPY/twice-knock-knock.mid\n",
      "Epoch 1/4\n",
      "34/34 [==============================] - 13s 378ms/step - loss: 5.5756\n",
      "Epoch 2/4\n",
      "34/34 [==============================] - 13s 374ms/step - loss: 5.2827\n",
      "Epoch 3/4\n",
      "34/34 [==============================] - 13s 383ms/step - loss: 5.1805\n",
      "Epoch 4/4\n",
      "34/34 [==============================] - 13s 375ms/step - loss: 5.0550\n"
     ]
    }
   ],
   "source": [
    "def train_Outro_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    Intro, Verse, Chorus, Outro = group_by_timestamp()\n",
    "\n",
    "    n_vocab = len(set(Outro))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(Outro, n_vocab)\n",
    "    \n",
    "    model = create_network(network_input, n_vocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"final-Outro-weights.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(network_input, network_output, epochs=4, batch_size=50, callbacks=callbacks_list)\n",
    "\n",
    "train_Outro_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_prediction(notes, pitchnames, n_vocab):\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    sequence_length = 40\n",
    "    network_input = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "    return (network_input, normalized_input)\n",
    "\n",
    "def choose_top(array):\n",
    "    ind = np.argpartition(array, -8)[-8:]\n",
    "    return (ind, array[ind])\n",
    "\n",
    "def generate_notes(model, network_input, pitchnames, n_vocab, length):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    print(len(pattern))\n",
    "    prediction_output = []\n",
    "\n",
    "    for note_index in range(length):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "        \n",
    "        ### Copy the line below from your above implementation.\n",
    "        prediction = model.predict(prediction_input)\n",
    "        \n",
    "        ind, array = choose_top(prediction[0])\n",
    "        \n",
    "        index = np.random.choice(ind)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "            \n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateParts(filename, weights, length):\n",
    "    notes = pickle.load(open(filename, 'rb'))\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences_prediction(notes, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    \n",
    "    ### Add a line to load the weights here\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab, length)\n",
    "    \n",
    "    return prediction_output\n",
    "    \n",
    "def generate():\n",
    "    prediction_output = []\n",
    "    \n",
    "    Intro = generateParts('Intro.p', 'final-Intro-weights.hdf5', 17)\n",
    "    Verse = generateParts('Verse.p', 'final-Verse-weights.hdf5', 59)\n",
    "    Chorus = generateParts('Chorus.p', 'final-Chorus-weights.hdf5',59)\n",
    "    Outro = generateParts('Outro.p', 'final-Outro-weights.hdf5',35)\n",
    "    \n",
    "    prediction_output = Intro + Verse + Chorus + Verse + Chorus + Verse + Outro\n",
    "    \n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "347\n"
     ]
    }
   ],
   "source": [
    "def generateDuration():\n",
    "    durations = pickle.load(open('offset.p', 'rb'))\n",
    "    pitchnames = sorted(set(item for item in durations))\n",
    "    n_vocab = len(set(durations))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences_prediction(durations, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    \n",
    "    ### Add a line to load the weights here\n",
    "    model.load_weights('final-duration-weights.hdf5')\n",
    "    \n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab, 347)\n",
    "    \n",
    "    return prediction_output\n",
    "\n",
    "offset_seq = generateDuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "def create_midi(prediction_output):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    for index, pattern in enumerate(prediction_output):\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            print(\"enter chord\")\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            #new_chord.duration.quarterLength = test_duration[index]\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            #new_note.duration.quarterLength = test_duration[index]\n",
    "            output_notes.append(new_note)\n",
    "        offset += 0.5\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='test_output.mid')\n",
    "    \n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
